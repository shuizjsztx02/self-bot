"""
PDFè§£æå™¨æµ‹è¯•è„šæœ¬

æµ‹è¯•ï¼š
1. æ–‡æ¡£ç‰¹å¾åˆ†æ
2. æ™ºèƒ½è·¯ç”±å†³ç­–
3. å„è§£æå™¨åŠŸèƒ½
4. å›é€€æœºåˆ¶
"""

import asyncio
import sys
import tempfile
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from rich.console import Console
from rich.panel import Panel
from rich.table import Table

console = Console()


async def test_feature_analyzer():
    """æµ‹è¯•æ–‡æ¡£ç‰¹å¾åˆ†æå™¨"""
    console.print(Panel.fit("ğŸ“Š æµ‹è¯•æ–‡æ¡£ç‰¹å¾åˆ†æå™¨", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFFeatureAnalyzer
    
    analyzer = PDFFeatureAnalyzer()
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    
    if not test_pdf_path.exists():
        console.print("[yellow]æµ‹è¯•æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¤ºä¾‹æµ‹è¯•...[/yellow]")
        
        test_pdf_path.mkdir(exist_ok=True)
        
        console.print("[cyan]è¯·å°†æµ‹è¯•PDFæ–‡ä»¶æ”¾å…¥ä»¥ä¸‹ç›®å½•è¿›è¡Œæµ‹è¯•:[/cyan]")
        console.print(f"  {test_pdf_path}")
        
        return False
    
    pdf_files = list(test_pdf_path.glob("*.pdf"))
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶[/yellow]")
        return False
    
    for pdf_file in pdf_files[:3]:
        console.print(f"\n[bold cyan]åˆ†æ: {pdf_file.name}[/bold cyan]")
        
        try:
            features = analyzer.analyze(str(pdf_file))
            
            table = Table(title=f"æ–‡æ¡£ç‰¹å¾ - {pdf_file.name}")
            table.add_column("ç‰¹å¾", style="cyan")
            table.add_column("å€¼", style="green")
            
            table.add_row("é¡µæ•°", str(features.page_count))
            table.add_row("æœ‰æ–‡æœ¬å±‚", "âœ“" if features.has_text_layer else "âœ—")
            table.add_row("æ–‡æœ¬å¯†åº¦", f"{features.text_density:.6f}")
            table.add_row("åŒ…å«å›¾ç‰‡", "âœ“" if features.has_images else "âœ—")
            table.add_row("å›¾ç‰‡æ¯”ä¾‹", f"{features.image_ratio:.2%}")
            table.add_row("åŒ…å«è¡¨æ ¼", "âœ“" if features.has_tables else "âœ—")
            table.add_row("å¸ƒå±€å¤æ‚åº¦", features.layout_complexity)
            table.add_row("æ˜¯å¦æ‰«æä»¶", "âœ“" if features.is_scanned else "âœ—")
            table.add_row("æ¨èè§£æå™¨", features.recommended_parser)
            table.add_row("ç½®ä¿¡åº¦", f"{features.confidence:.2%}")
            
            console.print(table)
            
        except Exception as e:
            console.print(f"[red]åˆ†æå¤±è´¥: {str(e)}[/red]")
    
    return True


async def test_parser_routing():
    """æµ‹è¯•æ™ºèƒ½è·¯ç”±"""
    console.print(Panel.fit("ğŸ”€ æµ‹è¯•æ™ºèƒ½è·¯ç”±", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import (
        PDFParser, DocumentFeatures, PDFFeatureAnalyzer
    )
    
    analyzer = PDFFeatureAnalyzer()
    
    test_cases = [
        DocumentFeatures(
            page_count=10,
            has_text_layer=True,
            text_density=0.02,
            has_images=False,
            image_ratio=0.0,
            has_tables=False,
            is_scanned=False,
            layout_complexity="simple",
        ),
        DocumentFeatures(
            page_count=5,
            has_text_layer=True,
            text_density=0.015,
            has_images=False,
            image_ratio=0.0,
            has_tables=True,
            is_scanned=False,
            layout_complexity="medium",
        ),
        DocumentFeatures(
            page_count=20,
            has_text_layer=False,
            text_density=0.001,
            has_images=True,
            image_ratio=0.95,
            has_tables=False,
            is_scanned=True,
            layout_complexity="simple",
        ),
        DocumentFeatures(
            page_count=15,
            has_text_layer=True,
            text_density=0.012,
            has_images=True,
            image_ratio=0.4,
            has_tables=True,
            is_scanned=False,
            layout_complexity="complex",
        ),
    ]
    
    expected_results = ["pymupdf", "mineru", "mineru", "mineru"]
    
    table = Table(title="è·¯ç”±å†³ç­–æµ‹è¯•")
    table.add_column("åœºæ™¯", style="cyan")
    table.add_column("é¢„æœŸ", style="yellow")
    table.add_column("å®é™…", style="green")
    table.add_column("ç»“æœ", style="bold")
    
    scenarios = [
        "çº¯æ–‡æœ¬PDF",
        "å«è¡¨æ ¼PDF (MinerUä¼˜å…ˆ)",
        "æ‰«æä»¶PDF (MinerUä¼˜å…ˆ)",
        "å¤æ‚å¸ƒå±€PDF (MinerUä¼˜å…ˆ)",
    ]
    
    for i, (features, expected, scenario) in enumerate(zip(test_cases, expected_results, scenarios)):
        recommended, confidence = analyzer._recommend_parser(features)
        
        match = "âœ“" if recommended == expected else "âœ—"
        table.add_row(scenario, expected, recommended, match)
    
    console.print(table)


async def test_available_parsers():
    """æµ‹è¯•å¯ç”¨è§£æå™¨æ£€æµ‹"""
    console.print(Panel.fit("ğŸ” æµ‹è¯•å¯ç”¨è§£æå™¨", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser
    
    parser = PDFParser()
    
    available = parser.get_available_parsers()
    
    table = Table(title="è§£æå™¨å¯ç”¨æ€§")
    table.add_column("è§£æå™¨", style="cyan")
    table.add_column("æè¿°", style="white")
    table.add_column("çŠ¶æ€", style="bold")
    
    for parser_type, desc in PDFParser.PARSER_TYPES.items():
        status = "âœ… å¯ç”¨" if parser_type in available else "âŒ æœªå®‰è£…"
        table.add_row(parser_type, desc[:30] + "...", status)
    
    console.print(table)
    
    return len(available) > 0


async def test_parse_flow():
    """æµ‹è¯•å®Œæ•´è§£ææµç¨‹"""
    console.print(Panel.fit("ğŸ“„ æµ‹è¯•å®Œæ•´è§£ææµç¨‹", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡è§£ææµ‹è¯•[/yellow]")
        return False
    
    parser = PDFParser(parser_type="auto")
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]è§£æ: {pdf_file.name}[/bold cyan]")
        
        try:
            result = await parser.parse(str(pdf_file))
            
            console.print(f"[green]âœ… è§£ææˆåŠŸ[/green]")
            console.print(f"  è§£æå™¨: {result.doc_metadata.get('parser', 'unknown')}")
            console.print(f"  å†…å®¹é•¿åº¦: {len(result.content)} å­—ç¬¦")
            console.print(f"  é¡µæ•°: {len(result.pages) if result.pages else 0}")
            
            if result.doc_metadata.get('auto_routed'):
                console.print(f"  è‡ªåŠ¨è·¯ç”±: {result.doc_metadata.get('recommended_parser')}")
                console.print(f"  ç½®ä¿¡åº¦: {result.doc_metadata.get('routing_confidence', 0):.2%}")
            
            if result.tables:
                console.print(f"  è¡¨æ ¼æ•°é‡: {len(result.tables)}")
            
            console.print(f"\n  [bold]å†…å®¹é¢„è§ˆ:[/bold]")
            console.print(f"  {result.content[:200]}...")
            
        except Exception as e:
            console.print(f"[red]âŒ è§£æå¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
    
    return True


async def test_mineru_layout_analysis():
    """æµ‹è¯•MinerUç‰ˆé¢åˆ†æ"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•MinerUç‰ˆé¢åˆ†æ", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, LayoutBlock
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡ç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="mineru")
    
    available = parser.get_available_parsers()
    if "mineru" not in available:
        console.print("[yellow]MinerUæœªå®‰è£…ï¼Œè·³è¿‡ç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]ç‰ˆé¢åˆ†æ: {pdf_file.name}[/bold cyan]")
        
        try:
            parsed_doc, layout_blocks = await parser.parse_with_layout(str(pdf_file))
            
            console.print(f"[green]âœ… ç‰ˆé¢åˆ†ææˆåŠŸ[/green]")
            console.print(f"  è§£ææ–‡æ¡£: {len(parsed_doc.content)} å­—ç¬¦")
            console.print(f"  ç‰ˆé¢å—æ•°é‡: {len(layout_blocks)}")
            
            block_types = {}
            for block in layout_blocks:
                block_types[block.block_type] = block_types.get(block.block_type, 0) + 1
            
            table = Table(title="ç‰ˆé¢å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for btype, count in sorted(block_types.items()):
                table.add_row(btype, str(count))
            
            console.print(table)
            
            if layout_blocks:
                console.print(f"\n  [bold]å‰5ä¸ªç‰ˆé¢å—:[/bold]")
                for i, block in enumerate(layout_blocks[:5]):
                    console.print(f"    [{i+1}] ç±»å‹: {block.block_type}, é¡µç : {block.page_number}")
                    console.print(f"        å†…å®¹é¢„è§ˆ: {block.content[:50]}...")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]MinerUæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ ç‰ˆé¢åˆ†æå¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_mineru_table_extraction():
    """æµ‹è¯•MinerUè¡¨æ ¼ç»“æ„è¯†åˆ«"""
    console.print(Panel.fit("ğŸ“Š æµ‹è¯•MinerUè¡¨æ ¼ç»“æ„è¯†åˆ«", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, TableStructure
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡è¡¨æ ¼æå–æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="mineru")
    
    available = parser.get_available_parsers()
    if "mineru" not in available:
        console.print("[yellow]MinerUæœªå®‰è£…ï¼Œè·³è¿‡è¡¨æ ¼æå–æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]è¡¨æ ¼æå–: {pdf_file.name}[/bold cyan]")
        
        try:
            tables = await parser.extract_tables_structured(str(pdf_file))
            
            console.print(f"[green]âœ… è¡¨æ ¼æå–æˆåŠŸ[/green]")
            console.print(f"  è¡¨æ ¼æ•°é‡: {len(tables)}")
            
            for i, table in enumerate(tables[:3]):
                console.print(f"\n  [bold]è¡¨æ ¼ {i+1}:[/bold]")
                console.print(f"    é¡µç : {table.page_number}")
                console.print(f"    ä½ç½®: {table.bbox}")
                if table.caption:
                    console.print(f"    æ ‡é¢˜: {table.caption}")
                if table.markdown_content:
                    lines = table.markdown_content.split('\n')[:5]
                    console.print(f"    Markdowné¢„è§ˆ:")
                    for line in lines:
                        console.print(f"      {line}")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]MinerUæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ è¡¨æ ¼æå–å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_mineru_semantic_chunking():
    """æµ‹è¯•MinerUè¯­ä¹‰åˆ†å—"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•MinerUè¯­ä¹‰åˆ†å—", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, SemanticChunk
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡è¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="mineru")
    
    available = parser.get_available_parsers()
    if "mineru" not in available:
        console.print("[yellow]MinerUæœªå®‰è£…ï¼Œè·³è¿‡è¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]è¯­ä¹‰åˆ†å—: {pdf_file.name}[/bold cyan]")
        
        try:
            chunks = await parser.semantic_chunking(
                str(pdf_file),
                max_chunk_size=500,
                respect_structure=True
            )
            
            console.print(f"[green]âœ… è¯­ä¹‰åˆ†å—æˆåŠŸ[/green]")
            console.print(f"  åˆ†å—æ•°é‡: {len(chunks)}")
            
            chunk_types = {}
            for chunk in chunks:
                chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1
            
            table = Table(title="åˆ†å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for ctype, count in sorted(chunk_types.items()):
                table.add_row(ctype, str(count))
            
            console.print(table)
            
            console.print(f"\n  [bold]å‰5ä¸ªåˆ†å—é¢„è§ˆ:[/bold]")
            for i, chunk in enumerate(chunks[:5]):
                console.print(f"\n    [{i+1}] ID: {chunk.chunk_id}")
                console.print(f"        ç±»å‹: {chunk.chunk_type}")
                console.print(f"        é¡µç : {chunk.page_numbers}")
                console.print(f"        ç« èŠ‚è·¯å¾„: {' > '.join(chunk.section_path) if chunk.section_path else 'æ— '}")
                console.print(f"        Tokenæ•°: {chunk.token_count}")
                console.print(f"        å†…å®¹é¢„è§ˆ: {chunk.content[:80]}...")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]MinerUæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ è¯­ä¹‰åˆ†å—å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_fallback_mechanism():
    """æµ‹è¯•å›é€€æœºåˆ¶"""
    console.print(Panel.fit("ğŸ”„ æµ‹è¯•å›é€€æœºåˆ¶", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser
    
    parser = PDFParser(
        parser_type="docling",
        fallback_order=["pymupdf", "pdfplumber"]
    )
    
    available = parser.get_available_parsers()
    
    console.print(f"[cyan]æŒ‡å®šè§£æå™¨: docling[/cyan]")
    console.print(f"[cyan]å›é€€é¡ºåº: pymupdf -> pdfplumber[/cyan]")
    console.print(f"[cyan]å¯ç”¨è§£æå™¨: {list(available.keys())}[/cyan]")
    
    if "pymupdf" in available:
        console.print("[green]âœ… å›é€€æœºåˆ¶å·²é…ç½®ï¼Œå½“doclingä¸å¯ç”¨æ—¶ä¼šè‡ªåŠ¨å›é€€[/green]")
    else:
        console.print("[yellow]âš ï¸ æ²¡æœ‰å¯ç”¨çš„å›é€€è§£æå™¨[/yellow]")
    
    return True


async def test_docling_layout_analysis():
    """æµ‹è¯•Doclingç‰ˆé¢åˆ†æ"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•Doclingç‰ˆé¢åˆ†æ", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, DoclingLayoutBlock
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡Doclingç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="docling")
    
    available = parser.get_available_parsers()
    if "docling" not in available:
        console.print("[yellow]Doclingæœªå®‰è£…ï¼Œè·³è¿‡ç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]Doclingç‰ˆé¢åˆ†æ: {pdf_file.name}[/bold cyan]")
        
        try:
            parsed_doc, layout_blocks = await parser.parse_with_layout(
                str(pdf_file), parser_type="docling"
            )
            
            console.print(f"[green]âœ… Doclingç‰ˆé¢åˆ†ææˆåŠŸ[/green]")
            console.print(f"  è§£ææ–‡æ¡£: {len(parsed_doc.content)} å­—ç¬¦")
            console.print(f"  ç‰ˆé¢å—æ•°é‡: {len(layout_blocks)}")
            
            block_types = {}
            for block in layout_blocks:
                block_types[block.label] = block_types.get(block.label, 0) + 1
            
            table = Table(title="Doclingç‰ˆé¢å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for btype, count in sorted(block_types.items()):
                table.add_row(btype, str(count))
            
            console.print(table)
            
            if layout_blocks:
                console.print(f"\n  [bold]å‰5ä¸ªç‰ˆé¢å—:[/bold]")
                for i, block in enumerate(layout_blocks[:5]):
                    console.print(f"    [{i+1}] ç±»å‹: {block.item_type}, æ ‡ç­¾: {block.label}, é¡µç : {block.page_number}")
                    console.print(f"        å†…å®¹é¢„è§ˆ: {block.content[:50]}...")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]Doclingæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ Doclingç‰ˆé¢åˆ†æå¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_docling_semantic_chunking():
    """æµ‹è¯•Doclingè¯­ä¹‰åˆ†å—"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•Doclingè¯­ä¹‰åˆ†å—", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, SemanticChunk
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡Doclingè¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="docling")
    
    available = parser.get_available_parsers()
    if "docling" not in available:
        console.print("[yellow]Doclingæœªå®‰è£…ï¼Œè·³è¿‡è¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]Doclingè¯­ä¹‰åˆ†å—: {pdf_file.name}[/bold cyan]")
        
        try:
            chunks = await parser.semantic_chunking(
                str(pdf_file),
                max_chunk_size=500,
                respect_structure=True,
                parser_type="docling"
            )
            
            console.print(f"[green]âœ… Doclingè¯­ä¹‰åˆ†å—æˆåŠŸ[/green]")
            console.print(f"  åˆ†å—æ•°é‡: {len(chunks)}")
            
            chunk_types = {}
            for chunk in chunks:
                chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1
            
            table = Table(title="Doclingåˆ†å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for ctype, count in sorted(chunk_types.items()):
                table.add_row(ctype, str(count))
            
            console.print(table)
            
            console.print(f"\n  [bold]å‰5ä¸ªåˆ†å—é¢„è§ˆ:[/bold]")
            for i, chunk in enumerate(chunks[:5]):
                console.print(f"\n    [{i+1}] ID: {chunk.chunk_id}")
                console.print(f"        ç±»å‹: {chunk.chunk_type}")
                console.print(f"        é¡µç : {chunk.page_numbers}")
                console.print(f"        ç« èŠ‚è·¯å¾„: {' > '.join(chunk.section_path) if chunk.section_path else 'æ— '}")
                console.print(f"        Tokenæ•°: {chunk.token_count}")
                console.print(f"        å†…å®¹é¢„è§ˆ: {chunk.content[:80]}...")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]Doclingæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ Doclingè¯­ä¹‰åˆ†å—å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_docling_export_formats():
    """æµ‹è¯•Doclingå¯¼å‡ºæ ¼å¼"""
    console.print(Panel.fit("ğŸ“¤ æµ‹è¯•Doclingå¯¼å‡ºæ ¼å¼", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡å¯¼å‡ºæ ¼å¼æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="docling")
    
    available = parser.get_available_parsers()
    if "docling" not in available:
        console.print("[yellow]Doclingæœªå®‰è£…ï¼Œè·³è¿‡å¯¼å‡ºæ ¼å¼æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]å¯¼å‡ºæ ¼å¼æµ‹è¯•: {pdf_file.name}[/bold cyan]")
        
        try:
            json_result = await parser.export_to_json(str(pdf_file), parser_type="docling")
            console.print(f"[green]âœ… JSONå¯¼å‡ºæˆåŠŸ[/green]")
            console.print(f"  JSONé”®: {list(json_result.keys())[:5]}...")
            
            html_result = await parser.export_to_html(str(pdf_file), parser_type="docling")
            console.print(f"[green]âœ… HTMLå¯¼å‡ºæˆåŠŸ[/green]")
            console.print(f"  HTMLé•¿åº¦: {len(html_result)} å­—ç¬¦")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]Doclingæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ å¯¼å‡ºæ ¼å¼æµ‹è¯•å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_docling_vlm_mode():
    """æµ‹è¯•Docling VLMæ¨¡å¼é…ç½®"""
    console.print(Panel.fit("ğŸ¤– æµ‹è¯•Docling VLMæ¨¡å¼é…ç½®", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, DoclingParser
    
    parser_standard = PDFParser(
        parser_type="docling",
        docling_config={"enable_ocr": True, "use_vlm": False}
    )
    
    parser_vlm = PDFParser(
        parser_type="docling",
        docling_config={"enable_ocr": True, "use_vlm": True, "vlm_model": "granite_docling"}
    )
    
    available = parser_standard.get_available_parsers()
    if "docling" not in available:
        console.print("[yellow]Doclingæœªå®‰è£…ï¼Œè·³è¿‡VLMæ¨¡å¼æµ‹è¯•[/yellow]")
        return True
    
    console.print("[green]âœ… æ ‡å‡†æ¨¡å¼é…ç½®æˆåŠŸ[/green]")
    console.print("  - OCR: å¯ç”¨")
    console.print("  - VLM: ç¦ç”¨")
    
    console.print("[green]âœ… VLMæ¨¡å¼é…ç½®æˆåŠŸ[/green]")
    console.print("  - OCR: å¯ç”¨")
    console.print("  - VLM: å¯ç”¨ (granite_docling)")
    
    console.print("\n[cyan]VLMæ¨¡å¼è¯´æ˜:[/cyan]")
    console.print("  - granite_docling: IBM Graniteè§†è§‰è¯­è¨€æ¨¡å‹")
    console.print("  - æ”¯æŒApple Silicon MLXåŠ é€Ÿ")
    console.print("  - é€‚ç”¨äºå¤æ‚å¸ƒå±€å’Œå›¾è¡¨ç†è§£")
    
    return True


async def test_ocr_layout_analysis():
    """æµ‹è¯•OCRç‰ˆé¢åˆ†æ"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•OCRç‰ˆé¢åˆ†æ (PP-Structure)", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, OCRLayoutBlock
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡OCRç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(
        parser_type="ocr",
        ocr_config={"enable_layout": True, "enable_table": True}
    )
    
    available = parser.get_available_parsers()
    if "ocr" not in available:
        console.print("[yellow]PaddleOCRæœªå®‰è£…ï¼Œè·³è¿‡ç‰ˆé¢åˆ†ææµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]OCRç‰ˆé¢åˆ†æ: {pdf_file.name}[/bold cyan]")
        
        try:
            parsed_doc, layout_blocks = await parser.parse_with_layout(
                str(pdf_file), parser_type="ocr"
            )
            
            console.print(f"[green]âœ… OCRç‰ˆé¢åˆ†ææˆåŠŸ[/green]")
            console.print(f"  è§£ææ–‡æ¡£: {len(parsed_doc.content)} å­—ç¬¦")
            console.print(f"  ç‰ˆé¢å—æ•°é‡: {len(layout_blocks)}")
            
            block_types = {}
            for block in layout_blocks:
                block_types[block.block_type] = block_types.get(block.block_type, 0) + 1
            
            table = Table(title="OCRç‰ˆé¢å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for btype, count in sorted(block_types.items()):
                table.add_row(btype, str(count))
            
            console.print(table)
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]PaddleOCRæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ OCRç‰ˆé¢åˆ†æå¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_ocr_table_extraction():
    """æµ‹è¯•OCRè¡¨æ ¼è¯†åˆ«"""
    console.print(Panel.fit("ğŸ“Š æµ‹è¯•OCRè¡¨æ ¼è¯†åˆ« (PP-Structure)", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡OCRè¡¨æ ¼æå–æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(
        parser_type="ocr",
        ocr_config={"enable_table": True}
    )
    
    available = parser.get_available_parsers()
    if "ocr" not in available:
        console.print("[yellow]PaddleOCRæœªå®‰è£…ï¼Œè·³è¿‡è¡¨æ ¼æå–æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]OCRè¡¨æ ¼æå–: {pdf_file.name}[/bold cyan]")
        
        try:
            tables = await parser.extract_tables_structured(str(pdf_file), parser_type="ocr")
            
            console.print(f"[green]âœ… OCRè¡¨æ ¼æå–æˆåŠŸ[/green]")
            console.print(f"  è¡¨æ ¼æ•°é‡: {len(tables)}")
            
            for i, table in enumerate(tables[:3]):
                console.print(f"\n  [bold]è¡¨æ ¼ {i+1}:[/bold]")
                console.print(f"    é¡µç : {table.page_number}")
                console.print(f"    ä½ç½®: {table.bbox}")
                if table.markdown_content:
                    lines = table.markdown_content.split('\n')[:5]
                    console.print(f"    Markdowné¢„è§ˆ:")
                    for line in lines:
                        console.print(f"      {line}")
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]PaddleOCRæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ OCRè¡¨æ ¼æå–å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_ocr_semantic_chunking():
    """æµ‹è¯•OCRè¯­ä¹‰åˆ†å—"""
    console.print(Panel.fit("ğŸ“ æµ‹è¯•OCRè¯­ä¹‰åˆ†å—", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, SemanticChunk
    
    test_pdf_path = Path(__file__).parent.parent / "test_files"
    pdf_files = list(test_pdf_path.glob("*.pdf")) if test_pdf_path.exists() else []
    
    if not pdf_files:
        console.print("[yellow]æœªæ‰¾åˆ°æµ‹è¯•PDFæ–‡ä»¶ï¼Œè·³è¿‡OCRè¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    parser = PDFParser(parser_type="ocr")
    
    available = parser.get_available_parsers()
    if "ocr" not in available:
        console.print("[yellow]PaddleOCRæœªå®‰è£…ï¼Œè·³è¿‡è¯­ä¹‰åˆ†å—æµ‹è¯•[/yellow]")
        return True
    
    for pdf_file in pdf_files[:1]:
        console.print(f"\n[bold cyan]OCRè¯­ä¹‰åˆ†å—: {pdf_file.name}[/bold cyan]")
        
        try:
            chunks = await parser.semantic_chunking(
                str(pdf_file),
                max_chunk_size=500,
                respect_structure=True,
                parser_type="ocr"
            )
            
            console.print(f"[green]âœ… OCRè¯­ä¹‰åˆ†å—æˆåŠŸ[/green]")
            console.print(f"  åˆ†å—æ•°é‡: {len(chunks)}")
            
            chunk_types = {}
            for chunk in chunks:
                chunk_types[chunk.chunk_type] = chunk_types.get(chunk.chunk_type, 0) + 1
            
            table = Table(title="OCRåˆ†å—ç±»å‹ç»Ÿè®¡")
            table.add_column("ç±»å‹", style="cyan")
            table.add_column("æ•°é‡", style="green")
            
            for ctype, count in sorted(chunk_types.items()):
                table.add_row(ctype, str(count))
            
            console.print(table)
            
            return True
            
        except ImportError as e:
            console.print(f"[yellow]PaddleOCRæœªå®‰è£…: {e}[/yellow]")
            return True
        except Exception as e:
            console.print(f"[red]âŒ OCRè¯­ä¹‰åˆ†å—å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
            return False
    
    return True


async def test_ocr_config():
    """æµ‹è¯•OCRé…ç½®é€‰é¡¹"""
    console.print(Panel.fit("âš™ï¸ æµ‹è¯•OCRé…ç½®é€‰é¡¹", style="bold blue"))
    
    from app.knowledge_base.parsers.pdf_parser import PDFParser, OCRParser
    
    parser_cpu = PDFParser(
        parser_type="ocr",
        ocr_config={"use_gpu": False, "lang": "ch", "enable_layout": True}
    )
    
    parser_gpu = PDFParser(
        parser_type="ocr",
        ocr_config={"use_gpu": True, "lang": "en", "enable_table": True}
    )
    
    available = parser_cpu.get_available_parsers()
    if "ocr" not in available:
        console.print("[yellow]PaddleOCRæœªå®‰è£…ï¼Œè·³è¿‡é…ç½®æµ‹è¯•[/yellow]")
        return True
    
    console.print("[green]âœ… CPUæ¨¡å¼é…ç½®æˆåŠŸ[/green]")
    console.print("  - GPU: ç¦ç”¨")
    console.print("  - è¯­è¨€: ä¸­æ–‡")
    console.print("  - ç‰ˆé¢åˆ†æ: å¯ç”¨")
    
    console.print("[green]âœ… GPUæ¨¡å¼é…ç½®æˆåŠŸ[/green]")
    console.print("  - GPU: å¯ç”¨")
    console.print("  - è¯­è¨€: è‹±æ–‡")
    console.print("  - è¡¨æ ¼è¯†åˆ«: å¯ç”¨")
    
    console.print("\n[cyan]PaddleOCRé…ç½®é€‰é¡¹:[/cyan]")
    console.print("  - lang: è¯­è¨€ (ch/en/korean/japanç­‰80+è¯­è¨€)")
    console.print("  - use_gpu: GPUåŠ é€Ÿ")
    console.print("  - enable_layout: ç‰ˆé¢åˆ†æ")
    console.print("  - enable_table: è¡¨æ ¼è¯†åˆ«")
    console.print("  - det_db_thresh: æ–‡æœ¬æ£€æµ‹é˜ˆå€¼")
    console.print("  - det_db_box_thresh: æ–‡æœ¬æ¡†é˜ˆå€¼")
    
    return True


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    console.print(Panel.fit(
        "[bold]ğŸ§ª PDFè§£æå™¨å®Œæ•´æµ‹è¯•[/bold]\n\n"
        "æµ‹è¯•é¡¹ç›®:\n"
        "1. æ–‡æ¡£ç‰¹å¾åˆ†æ\n"
        "2. æ™ºèƒ½è·¯ç”±å†³ç­–\n"
        "3. è§£æå™¨å¯ç”¨æ€§æ£€æµ‹\n"
        "4. å®Œæ•´è§£ææµç¨‹\n"
        "5. å›é€€æœºåˆ¶\n"
        "6. MinerUç‰ˆé¢åˆ†æ\n"
        "7. MinerUè¡¨æ ¼ç»“æ„è¯†åˆ«\n"
        "8. MinerUè¯­ä¹‰åˆ†å—\n"
        "9. Doclingç‰ˆé¢åˆ†æ\n"
        "10. Doclingè¯­ä¹‰åˆ†å—\n"
        "11. Doclingå¯¼å‡ºæ ¼å¼\n"
        "12. Docling VLMæ¨¡å¼\n"
        "13. OCRç‰ˆé¢åˆ†æ (PP-Structure)\n"
        "14. OCRè¡¨æ ¼è¯†åˆ«\n"
        "15. OCRè¯­ä¹‰åˆ†å—\n"
        "16. OCRé…ç½®é€‰é¡¹",
        style="bold magenta",
    ))
    
    results = []
    
    console.print("\n")
    result1 = await test_available_parsers()
    results.append(("è§£æå™¨å¯ç”¨æ€§", result1))
    
    console.print("\n")
    result2 = await test_parser_routing()
    results.append(("æ™ºèƒ½è·¯ç”±", True))
    
    console.print("\n")
    result3 = await test_feature_analyzer()
    results.append(("ç‰¹å¾åˆ†æ", result3 or True))
    
    console.print("\n")
    result4 = await test_parse_flow()
    results.append(("è§£ææµç¨‹", result4 or True))
    
    console.print("\n")
    result5 = await test_fallback_mechanism()
    results.append(("å›é€€æœºåˆ¶", result5))
    
    console.print("\n")
    result6 = await test_mineru_layout_analysis()
    results.append(("MinerUç‰ˆé¢åˆ†æ", result6))
    
    console.print("\n")
    result7 = await test_mineru_table_extraction()
    results.append(("MinerUè¡¨æ ¼æå–", result7))
    
    console.print("\n")
    result8 = await test_mineru_semantic_chunking()
    results.append(("MinerUè¯­ä¹‰åˆ†å—", result8))
    
    console.print("\n")
    result9 = await test_docling_layout_analysis()
    results.append(("Doclingç‰ˆé¢åˆ†æ", result9))
    
    console.print("\n")
    result10 = await test_docling_semantic_chunking()
    results.append(("Doclingè¯­ä¹‰åˆ†å—", result10))
    
    console.print("\n")
    result11 = await test_docling_export_formats()
    results.append(("Doclingå¯¼å‡ºæ ¼å¼", result11))
    
    console.print("\n")
    result12 = await test_docling_vlm_mode()
    results.append(("Docling VLMæ¨¡å¼", result12))
    
    console.print("\n")
    result13 = await test_ocr_layout_analysis()
    results.append(("OCRç‰ˆé¢åˆ†æ", result13))
    
    console.print("\n")
    result14 = await test_ocr_table_extraction()
    results.append(("OCRè¡¨æ ¼æå–", result14))
    
    console.print("\n")
    result15 = await test_ocr_semantic_chunking()
    results.append(("OCRè¯­ä¹‰åˆ†å—", result15))
    
    console.print("\n")
    result16 = await test_ocr_config()
    results.append(("OCRé…ç½®é€‰é¡¹", result16))
    
    console.print("\n")
    console.print(Panel.fit(
        "[bold]ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»[/bold]",
        style="bold green",
    ))
    
    table = Table(title="")
    table.add_column("æµ‹è¯•é¡¹ç›®", style="cyan")
    table.add_column("çŠ¶æ€", style="bold")
    
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âš ï¸ è·³è¿‡"
        table.add_row(name, status)
    
    console.print(table)
    
    passed = sum(1 for _, s in results if s)
    total = len(results)
    
    console.print(f"\n[bold green]é€šè¿‡: {passed}/{total}[/bold green]")


if __name__ == "__main__":
    asyncio.run(run_all_tests())
