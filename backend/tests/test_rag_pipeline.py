"""
RagAgent å®Œæ•´Pipelineæµ‹è¯•è„šæœ¬

æµ‹è¯•æµç¨‹ï¼š
1. åˆ›å»ºæµ‹è¯•çŸ¥è¯†åº“
2. ä¸Šä¼ æµ‹è¯•æ–‡æ¡£
3. æ–‡æ¡£è§£æä¸åˆ†å—
4. å‘é‡åµŒå…¥ä¸å­˜å‚¨
5. çŸ¥è¯†åº“æ£€ç´¢
6. RAGå¢å¼ºå¯¹è¯
"""

import asyncio
import sys
import os
import tempfile
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

console = Console()


async def test_knowledge_base_creation():
    """
    æµ‹è¯•çŸ¥è¯†åº“åˆ›å»º
    """
    console.print(Panel.fit("ğŸ“ æµ‹è¯•çŸ¥è¯†åº“åˆ›å»º", style="bold blue"))
    
    from app.knowledge_base.services import KnowledgeBaseService
    from app.knowledge_base.schemas import KnowledgeBaseCreate
    from app.db.session import get_db
    
    async for db in get_db():
        kb_service = KnowledgeBaseService(db)
        
        kb_data = KnowledgeBaseCreate(
            name="æµ‹è¯•çŸ¥è¯†åº“",
            description="ç”¨äºæµ‹è¯•RagAgent Pipelineçš„çŸ¥è¯†åº“",
            embedding_model="BAAI/bge-base-zh-v1.5",
            chunk_size=500,
            chunk_overlap=50,
        )
        
        try:
            kb = await kb_service.create(kb_data, owner_id="test_user")
            
            console.print(f"[bold green]âœ… çŸ¥è¯†åº“åˆ›å»ºæˆåŠŸ[/bold green]")
            console.print(f"  ID: {kb.id}")
            console.print(f"  åç§°: {kb.name}")
            console.print(f"  åµŒå…¥æ¨¡å‹: {kb.embedding_model}")
            console.print(f"  åˆ†å—å¤§å°: {kb.chunk_size}")
            
            return kb.id, db, kb_service
            
        except Exception as e:
            console.print(f"[bold red]âŒ çŸ¥è¯†åº“åˆ›å»ºå¤±è´¥: {str(e)}[/bold red]")
            import traceback
            traceback.print_exc()
            return None, db, None


async def test_document_parsing():
    """
    æµ‹è¯•æ–‡æ¡£è§£æ
    """
    console.print(Panel.fit("ğŸ“„ æµ‹è¯•æ–‡æ¡£è§£æ", style="bold blue"))
    
    from app.knowledge_base.parsers import ParserRouter
    
    parser_router = ParserRouter()
    
    with tempfile.TemporaryDirectory() as tmpdir:
        md_file = Path(tmpdir) / "test.md"
        md_content = """# æµ‹è¯•æ–‡æ¡£

## ç¬¬ä¸€ç«  ä»‹ç»

è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºæµ‹è¯•RagAgentçš„æ–‡æ¡£è§£æåŠŸèƒ½ã€‚

### 1.1 èƒŒæ™¯

çŸ¥è¯†åº“ç³»ç»Ÿæ˜¯ä¼ä¸šä¿¡æ¯åŒ–å»ºè®¾çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚å®ƒå¯ä»¥å¸®åŠ©ä¼ä¸šï¼š
- æ•´åˆåˆ†æ•£çš„çŸ¥è¯†èµ„æº
- æé«˜çŸ¥è¯†å¤ç”¨æ•ˆç‡
- é™ä½çŸ¥è¯†ä¼ é€’æˆæœ¬

### 1.2 ç›®æ ‡

æœ¬ç³»ç»Ÿçš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªé«˜æ•ˆã€æ˜“ç”¨çš„çŸ¥è¯†ç®¡ç†å¹³å°ã€‚

## ç¬¬äºŒç«  æŠ€æœ¯æ¶æ„

ç³»ç»Ÿé‡‡ç”¨ä»¥ä¸‹æŠ€æœ¯æ ˆï¼š
1. åç«¯ï¼šPython + FastAPI
2. å‘é‡æ•°æ®åº“ï¼šChromaDB
3. åµŒå…¥æ¨¡å‹ï¼šBAAI/bge-base-zh-v1.5

### 2.1 æ ¸å¿ƒæ¨¡å—

- æ–‡æ¡£è§£ææ¨¡å—
- å‘é‡åµŒå…¥æ¨¡å—
- æ£€ç´¢æ¨¡å—
- RAGå¢å¼ºæ¨¡å—

## ç¬¬ä¸‰ç«  ä½¿ç”¨è¯´æ˜

### 3.1 æ–‡æ¡£ä¸Šä¼ 

ç”¨æˆ·å¯ä»¥é€šè¿‡APIä¸Šä¼ æ–‡æ¡£ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
- Markdown (.md)
- PDF (.pdf)
- Word (.docx)
- Excel (.xlsx)
- PowerPoint (.pptx)

### 3.2 çŸ¥è¯†æ£€ç´¢

ç³»ç»Ÿæ”¯æŒè¯­ä¹‰æ£€ç´¢ï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥è‡ªç„¶è¯­è¨€æŸ¥è¯¢ã€‚
"""
        md_file.write_text(md_content, encoding="utf-8")
        
        txt_file = Path(tmpdir) / "test.txt"
        txt_content = """
å…¬å¸æŠ¥é”€æµç¨‹è¯´æ˜

ä¸€ã€æŠ¥é”€èŒƒå›´
å‘˜å·¥å› å…¬äº§ç”Ÿçš„ä»¥ä¸‹è´¹ç”¨å¯ä»¥ç”³è¯·æŠ¥é”€ï¼š
1. äº¤é€šè´¹ç”¨
2. ä½å®¿è´¹ç”¨
3. é¤é¥®è´¹ç”¨
4. åŠå…¬ç”¨å“è´¹ç”¨

äºŒã€æŠ¥é”€æµç¨‹
1. å¡«å†™æŠ¥é”€ç”³è¯·å•
2. é™„ä¸ŠåŸå§‹å‘ç¥¨
3. æäº¤éƒ¨é—¨ä¸»ç®¡å®¡æ‰¹
4. è´¢åŠ¡éƒ¨é—¨å®¡æ ¸
5. æŠ¥é”€æ¬¾é¡¹å‘æ”¾

ä¸‰ã€æ³¨æ„äº‹é¡¹
- å‘ç¥¨å¿…é¡»çœŸå®æœ‰æ•ˆ
- æŠ¥é”€é‡‘é¢è¶…è¿‡5000å…ƒéœ€è¦æ€»ç»ç†å®¡æ‰¹
- æŠ¥é”€æœŸé™ä¸ºè´¹ç”¨å‘ç”Ÿå30å¤©å†…
"""
        txt_file.write_text(txt_content, encoding="utf-8")
        
        results = {}
        
        console.print("\n[bold cyan]è§£æ Markdown æ–‡æ¡£...[/bold cyan]")
        try:
            md_doc = await parser_router.parse(str(md_file))
            console.print(f"  å†…å®¹é•¿åº¦: {len(md_doc.content)} å­—ç¬¦")
            console.print(f"  ç« èŠ‚æ•°é‡: {len(md_doc.sections) if md_doc.sections else 0}")
            console.print(f"  å…ƒæ•°æ®: {md_doc.doc_metadata}")
            results["md"] = md_doc
        except Exception as e:
            console.print(f"  [red]è§£æå¤±è´¥: {str(e)}[/red]")
        
        console.print("\n[bold cyan]è§£æ TXT æ–‡æ¡£...[/bold cyan]")
        try:
            txt_doc = await parser_router.parse(str(txt_file))
            console.print(f"  å†…å®¹é•¿åº¦: {len(txt_doc.content)} å­—ç¬¦")
            console.print(f"  å…ƒæ•°æ®: {txt_doc.doc_metadata}")
            results["txt"] = txt_doc
        except Exception as e:
            console.print(f"  [red]è§£æå¤±è´¥: {str(e)}[/red]")
        
        console.print(f"\n[bold green]âœ… æ–‡æ¡£è§£ææµ‹è¯•å®Œæˆ[/bold green]")
        
        return results, tmpdir


async def test_chunking(parsed_docs):
    """
    æµ‹è¯•æ–‡æ¡£åˆ†å—
    """
    console.print(Panel.fit("âœ‚ï¸ æµ‹è¯•æ–‡æ¡£åˆ†å—", style="bold blue"))
    
    from app.knowledge_base.parsers import ParserRouter
    
    parser_router = ParserRouter()
    
    all_chunks = []
    
    for doc_type, parsed_doc in parsed_docs.items():
        console.print(f"\n[bold cyan]åˆ†å— {doc_type} æ–‡æ¡£...[/bold cyan]")
        
        try:
            chunks = parser_router.chunk_parsed_document(parsed_doc, chunk_size=300, overlap=50)
            
            console.print(f"  åˆ†å—æ•°é‡: {len(chunks)}")
            
            for i, chunk in enumerate(chunks[:3]):
                console.print(f"\n  [bold]åˆ†å— {i+1}:[/bold]")
                console.print(f"    å†…å®¹é¢„è§ˆ: {chunk.content[:100]}...")
                console.print(f"    Tokenæ•°: {chunk.token_count}")
                if chunk.page_number:
                    console.print(f"    é¡µç : {chunk.page_number}")
                if chunk.section_title:
                    console.print(f"    ç« èŠ‚: {chunk.section_title}")
            
            all_chunks.extend([(doc_type, chunk) for chunk in chunks])
            
        except Exception as e:
            console.print(f"  [red]åˆ†å—å¤±è´¥: {str(e)}[/red]")
            import traceback
            traceback.print_exc()
    
    console.print(f"\n[bold green]âœ… æ–‡æ¡£åˆ†å—æµ‹è¯•å®Œæˆï¼Œå…± {len(all_chunks)} ä¸ªåˆ†å—[/bold green]")
    
    return all_chunks


async def test_embedding(chunks):
    """
    æµ‹è¯•å‘é‡åµŒå…¥
    """
    console.print(Panel.fit("ğŸ”¢ æµ‹è¯•å‘é‡åµŒå…¥", style="bold blue"))
    
    from app.knowledge_base.services.embedding import EmbeddingService
    
    embedding_service = EmbeddingService()
    
    console.print(f"\n[bold cyan]åµŒå…¥æ¨¡å‹: {embedding_service.model_name}[/bold cyan]")
    console.print(f"[bold cyan]åµŒå…¥ç»´åº¦: {embedding_service.get_embedding_dim()}[/bold cyan]")
    
    test_texts = [chunk[1].content for chunk in chunks[:5]]
    
    console.print(f"\n[bold cyan]æ­£åœ¨åµŒå…¥ {len(test_texts)} ä¸ªæ–‡æœ¬...[/bold cyan]")
    
    try:
        embeddings = await embedding_service.embed_texts(test_texts)
        
        console.print(f"[bold green]âœ… åµŒå…¥æˆåŠŸ[/bold green]")
        console.print(f"  åµŒå…¥æ•°é‡: {len(embeddings)}")
        console.print(f"  åµŒå…¥ç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
        
        return embeddings
        
    except Exception as e:
        console.print(f"[bold red]âŒ åµŒå…¥å¤±è´¥: {str(e)}[/bold red]")
        import traceback
        traceback.print_exc()
        return None


async def test_vector_store(kb_id, chunks, embeddings):
    """
    æµ‹è¯•å‘é‡å­˜å‚¨
    """
    console.print(Panel.fit("ğŸ’¾ æµ‹è¯•å‘é‡å­˜å‚¨", style="bold blue"))
    
    from app.knowledge_base.vector_store import VectorStoreFactory
    from app.knowledge_base.services.embedding import EmbeddingService
    import uuid
    
    vector_store = VectorStoreFactory.create("chroma")
    embedding_service = EmbeddingService()
    
    collection_name = f"kb_{kb_id.replace('-', '_')}"
    
    console.print(f"\n[bold cyan]åˆ›å»ºå‘é‡é›†åˆ: {collection_name}[/bold cyan]")
    
    try:
        await vector_store.create_collection(collection_name)
        console.print("[bold green]âœ… å‘é‡é›†åˆåˆ›å»ºæˆåŠŸ[/bold green]")
    except Exception as e:
        console.print(f"[yellow]é›†åˆå¯èƒ½å·²å­˜åœ¨: {str(e)}[/yellow]")
    
    console.print(f"\n[bold cyan]æ’å…¥ {len(chunks)} ä¸ªå‘é‡...[/bold cyan]")
    
    ids = [str(uuid.uuid4()) for _ in chunks]
    all_embeddings = await embedding_service.embed_texts([c[1].content for c in chunks])
    metadatas = [
        {
            "doc_type": c[0],
            "chunk_index": c[1].chunk_index if hasattr(c[1], 'chunk_index') else i,
            "section_title": c[1].section_title or "",
        }
        for i, c in enumerate(chunks)
    ]
    documents = [c[1].content for c in chunks]
    
    try:
        inserted_ids = await vector_store.insert(
            collection_name=collection_name,
            ids=ids,
            embeddings=all_embeddings,
            metadatas=metadatas,
            documents=documents,
        )
        
        console.print(f"[bold green]âœ… æˆåŠŸæ’å…¥ {len(inserted_ids)} ä¸ªå‘é‡[/bold green]")
        
        count = await vector_store.count(collection_name)
        console.print(f"  å½“å‰å‘é‡æ•°é‡: {count}")
        
        return vector_store, collection_name
        
    except Exception as e:
        console.print(f"[bold red]âŒ å‘é‡æ’å…¥å¤±è´¥: {str(e)}[/bold red]")
        import traceback
        traceback.print_exc()
        return None, None


async def test_search(vector_store, collection_name):
    """
    æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢
    """
    console.print(Panel.fit("ğŸ” æµ‹è¯•çŸ¥è¯†åº“æ£€ç´¢", style="bold blue"))
    
    from app.knowledge_base.services.embedding import EmbeddingService
    
    embedding_service = EmbeddingService()
    
    test_queries = [
        "æŠ¥é”€æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
        "ç³»ç»Ÿä½¿ç”¨ä»€ä¹ˆæŠ€æœ¯æ ˆï¼Ÿ",
        "å¦‚ä½•ä¸Šä¼ æ–‡æ¡£ï¼Ÿ",
    ]
    
    for query in test_queries:
        console.print(f"\n[bold cyan]æŸ¥è¯¢: {query}[/bold cyan]")
        
        try:
            query_embedding = await embedding_service.embed_text(query)
            
            results = await vector_store.search(
                collection_name=collection_name,
                query_embedding=query_embedding,
                top_k=3,
            )
            
            if results:
                for i, result in enumerate(results):
                    score = 1 - result.get("distance", 0)
                    content = result.get("document", "")[:200]
                    console.print(f"\n  [bold]ç»“æœ {i+1}[/bold] (ç›¸å…³åº¦: {score:.3f})")
                    console.print(f"  {content}...")
            else:
                console.print("  [yellow]æœªæ‰¾åˆ°ç›¸å…³ç»“æœ[/yellow]")
                
        except Exception as e:
            console.print(f"  [red]æ£€ç´¢å¤±è´¥: {str(e)}[/red]")
    
    console.print(f"\n[bold green]âœ… çŸ¥è¯†åº“æ£€ç´¢æµ‹è¯•å®Œæˆ[/bold green]")


async def test_rag_agent():
    """
    æµ‹è¯•RagAgentå®Œæ•´åŠŸèƒ½
    """
    console.print(Panel.fit("ğŸ¤– æµ‹è¯•RagAgent", style="bold blue"))
    
    from app.langchain.agents.rag_agent import RagAgent
    
    agent = RagAgent(user_id="test_user")
    
    console.print("\n[bold cyan]æµ‹è¯• RagAgent å·¥å…·å°è£…...[/bold cyan]")
    
    try:
        tool = agent.as_tool()
        console.print(f"  å·¥å…·åç§°: {tool.name}")
        console.print(f"  å·¥å…·æè¿°: {tool.description[:100]}...")
        console.print("[bold green]âœ… å·¥å…·å°è£…æˆåŠŸ[/bold green]")
    except Exception as e:
        console.print(f"[bold red]âŒ å·¥å…·å°è£…å¤±è´¥: {str(e)}[/bold red]")
    
    console.print("\n[bold cyan]æµ‹è¯• RagAgent æ£€ç´¢åŠŸèƒ½...[/bold cyan]")
    
    try:
        results = await agent.search("æŠ¥é”€æµç¨‹", top_k=3)
        
        if results:
            console.print(f"  æ£€ç´¢ç»“æœæ•°é‡: {len(results)}")
            for i, r in enumerate(results[:2]):
                console.print(f"\n  [bold]ç»“æœ {i+1}[/bold]")
                console.print(f"    ç›¸å…³åº¦: {r.score:.3f}")
                console.print(f"    å†…å®¹: {r.content[:100]}...")
        else:
            console.print("  [yellow]æœªæ‰¾åˆ°ç›¸å…³ç»“æœï¼ˆå¯èƒ½çŸ¥è¯†åº“ä¸ºç©ºï¼‰[/yellow]")
        
        console.print("[bold green]âœ… RagAgent æ£€ç´¢æµ‹è¯•å®Œæˆ[/bold green]")
        
    except Exception as e:
        console.print(f"[bold red]âŒ RagAgent æ£€ç´¢å¤±è´¥: {str(e)}[/bold red]")
        import traceback
        traceback.print_exc()
    
    console.print("\n[bold cyan]æµ‹è¯• RagAgent RAGä¸Šä¸‹æ–‡ç”Ÿæˆ...[/bold cyan]")
    
    try:
        context = await agent.get_rag_context("æŠ¥é”€æµç¨‹", top_k=3)
        
        if context:
            console.print(f"  ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)} å­—ç¬¦")
            console.print(f"  ä¸Šä¸‹æ–‡é¢„è§ˆ:\n{context[:500]}...")
        else:
            console.print("  [yellow]æœªç”Ÿæˆä¸Šä¸‹æ–‡ï¼ˆå¯èƒ½çŸ¥è¯†åº“ä¸ºç©ºï¼‰[/yellow]")
        
        console.print("[bold green]âœ… RAGä¸Šä¸‹æ–‡ç”Ÿæˆæµ‹è¯•å®Œæˆ[/bold green]")
        
    except Exception as e:
        console.print(f"[bold red]âŒ RAGä¸Šä¸‹æ–‡ç”Ÿæˆå¤±è´¥: {str(e)}[/bold red]")


async def test_supervisor_integration():
    """
    æµ‹è¯•SupervisorAgenté›†æˆ
    """
    console.print(Panel.fit("ğŸ”€ æµ‹è¯•SupervisorAgenté›†æˆ", style="bold blue"))
    
    from app.langchain.agents.supervisor_agent import SupervisorAgent
    from app.langchain.routers.intent_classifier import QueryIntent
    
    agent = SupervisorAgent(
        provider="deepseek",
        user_id="test_user",
    )
    
    test_queries = [
        ("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", QueryIntent.GENERAL_CHAT),
        ("å…¬å¸çš„æŠ¥é”€æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ", QueryIntent.KB_QUERY),
        ("å¸®æˆ‘å†™ä¸€ä¸ªPythonçˆ¬è™«", QueryIntent.CODE_TASK),
    ]
    
    console.print("\n[bold cyan]æµ‹è¯•æ„å›¾åˆ†ç±»å’Œè·¯ç”±...[/bold cyan]")
    
    for query, expected_intent in test_queries:
        console.print(f"\n[bold]æŸ¥è¯¢:[/bold] {query}")
        
        try:
            result = await agent.intent_classifier.classify(query)
            
            match = "âœ“" if result.intent == expected_intent else "âœ—"
            console.print(f"  é¢„æœŸæ„å›¾: {expected_intent.value}")
            console.print(f"  å®é™…æ„å›¾: {result.intent.value} {match}")
            console.print(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
            
        except Exception as e:
            console.print(f"  [red]åˆ†ç±»å¤±è´¥: {str(e)}[/red]")
    
    console.print(f"\n[bold green]âœ… SupervisorAgenté›†æˆæµ‹è¯•å®Œæˆ[/bold green]")


async def run_pipeline_test():
    """
    è¿è¡Œå®Œæ•´Pipelineæµ‹è¯•
    """
    console.print(Panel.fit(
        "[bold]ğŸš€ RagAgent å®Œæ•´Pipelineæµ‹è¯•[/bold]\n\n"
        "æµ‹è¯•æµç¨‹:\n"
        "1. åˆ›å»ºçŸ¥è¯†åº“\n"
        "2. æ–‡æ¡£è§£æ\n"
        "3. æ–‡æ¡£åˆ†å—\n"
        "4. å‘é‡åµŒå…¥\n"
        "5. å‘é‡å­˜å‚¨\n"
        "6. çŸ¥è¯†åº“æ£€ç´¢\n"
        "7. RagAgentåŠŸèƒ½\n"
        "8. SupervisorAgenté›†æˆ",
        style="bold magenta",
    ))
    
    from app.db.session import init_kb_tables
    
    console.print("\n[bold cyan]åˆå§‹åŒ–çŸ¥è¯†åº“æ•°æ®åº“è¡¨...[/bold cyan]")
    try:
        await init_kb_tables()
        console.print("[bold green]âœ… æ•°æ®åº“è¡¨åˆå§‹åŒ–æˆåŠŸ[/bold green]")
    except Exception as e:
        console.print(f"[yellow]æ•°æ®åº“è¡¨åˆå§‹åŒ–è­¦å‘Š: {str(e)}[/yellow]")
    
    results = []
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        
        task1 = progress.add_task("åˆ›å»ºçŸ¥è¯†åº“...", total=None)
        kb_id, db, kb_service = await test_knowledge_base_creation()
        results.append(("çŸ¥è¯†åº“åˆ›å»º", kb_id is not None))
        progress.remove_task(task1)
        
        task2 = progress.add_task("è§£ææ–‡æ¡£...", total=None)
        parsed_docs, tmpdir = await test_document_parsing()
        results.append(("æ–‡æ¡£è§£æ", len(parsed_docs) > 0))
        progress.remove_task(task2)
        
        task3 = progress.add_task("æ–‡æ¡£åˆ†å—...", total=None)
        chunks = await test_chunking(parsed_docs)
        results.append(("æ–‡æ¡£åˆ†å—", len(chunks) > 0))
        progress.remove_task(task3)
        
        task4 = progress.add_task("å‘é‡åµŒå…¥...", total=None)
        embeddings = await test_embedding(chunks)
        results.append(("å‘é‡åµŒå…¥", embeddings is not None))
        progress.remove_task(task4)
        
        if kb_id and chunks:
            task5 = progress.add_task("å‘é‡å­˜å‚¨...", total=None)
            vector_store, collection_name = await test_vector_store(kb_id, chunks, embeddings)
            results.append(("å‘é‡å­˜å‚¨", vector_store is not None))
            progress.remove_task(task5)
            
            if vector_store:
                task6 = progress.add_task("çŸ¥è¯†åº“æ£€ç´¢...", total=None)
                await test_search(vector_store, collection_name)
                results.append(("çŸ¥è¯†åº“æ£€ç´¢", True))
                progress.remove_task(task6)
        else:
            results.append(("å‘é‡å­˜å‚¨", False))
            results.append(("çŸ¥è¯†åº“æ£€ç´¢", False))
        
        task7 = progress.add_task("æµ‹è¯•RagAgent...", total=None)
        await test_rag_agent()
        results.append(("RagAgentåŠŸèƒ½", True))
        progress.remove_task(task7)
        
        task8 = progress.add_task("æµ‹è¯•SupervisorAgent...", total=None)
        await test_supervisor_integration()
        results.append(("SupervisorAgenté›†æˆ", True))
        progress.remove_task(task8)
    
    console.print("\n")
    console.print(Panel.fit(
        "[bold]ğŸ“Š Pipelineæµ‹è¯•ç»“æœæ±‡æ€»[/bold]",
        style="bold green",
    ))
    
    table = Table(title="")
    table.add_column("æµ‹è¯•é˜¶æ®µ", style="cyan")
    table.add_column("çŠ¶æ€", style="bold")
    
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        table.add_row(name, status)
    
    console.print(table)
    
    passed = sum(1 for _, s in results if s)
    total = len(results)
    
    console.print(f"\n[bold green]é€šè¿‡: {passed}/{total}[/bold green]")


if __name__ == "__main__":
    asyncio.run(run_pipeline_test())
